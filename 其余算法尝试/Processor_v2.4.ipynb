{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## README"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "V2.4 update: \n",
    "* increased the low level of noise\n",
    "* Increased train-set to all 186 different types of MOF\n",
    "* Added more experimental data to the test-set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the Ver. 2.2 for the data pre-processor. After running this program, multiple sets of the spectra data shall be created. \n",
    "\n",
    "1. Multiple \"experimental\" spectra will be generated using the original processor with Gaussian mixture distribution.\n",
    "2. Transformation of the data including sigmoid transformation, squashed spectra, ReLU instead of normalization\n",
    "\n",
    "The output of the program shall be several pickle files with different transformation performed on the simulated spectra. Spectra simulation will also provide multiple options, including low noise, medium noise and high noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import random\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "loc = 'Train_data/'\n",
    "files = os.listdir(loc) # Which files are under the ZIF folder\n",
    "\n",
    "class data_processes(object):\n",
    "    \n",
    "    def __init__(self, x, y, label): # Taking the values into the Python class\n",
    "        self.grid = x\n",
    "        self.values = y\n",
    "        self.label = label\n",
    "        \n",
    "    def max_min(self): # Max-min scaler for the values\n",
    "        self.grid = (self.grid - np.min(self.grid)) / (np.max(self.grid) - np.min(self.grid))\n",
    "        self.values = (self.values - np.min(self.values)) / (np.max(self.values) - np.min(self.values))\n",
    "        \n",
    "    def ReLU(self):\n",
    "        self.values = np.maximum(0, self.values)\n",
    "        \n",
    "    def plot(self): # Make plots of the spectra\n",
    "        plt.plot(self.grid, self.values, label = self.label)\n",
    "        \n",
    "    def fit_grid(self, step_size): # Interpolate the spectra to normalize the grids\n",
    "        self.grid_step = step_size\n",
    "        fitting_grids = np.arange(0,1,step_size)\n",
    "\n",
    "        new_values = []\n",
    "        for g in fitting_grids:\n",
    "            idx = np.argmin(abs(g - self.grid[:-1]))\n",
    "            interp_x1 = self.grid[idx]\n",
    "            interp_y1 =  self.values[idx]\n",
    "            if (g - interp_x1) > 0:\n",
    "                interp_x2 = self.grid[idx + 1]\n",
    "                interp_y2 = self.values[idx + 1]\n",
    "            elif (g - interp_x1) < 0:\n",
    "                interp_x2 = self.grid[idx - 1]\n",
    "                interp_y2 = self.values[idx - 1]\n",
    "            else:\n",
    "                new_values.append(interp_y1)\n",
    "                continue\n",
    "\n",
    "            new_values.append(np.maximum((interp_y2 - interp_y1) / (interp_x2 - interp_x1)\\\n",
    "                                            *(g - interp_x1) + interp_y1, 0.0))\n",
    "        \n",
    "        fitting_grids = np.append(fitting_grids, 1)\n",
    "        new_values.append(self.values[-1])\n",
    "        \n",
    "        self.grid = fitting_grids\n",
    "        self.values = new_values\n",
    "\n",
    "    def back_cancel(self, scaler): # Cancel the background\n",
    "        self.values[self.values <= (np.mean(self.values) - scaler * np.std(self.values))] = 0.0\n",
    "        \n",
    "    def der_1st(self): # Getting the 1st order derivatives\n",
    "        self.der1 = []\n",
    "        for i in range(2,  len(self.grid)):\n",
    "            self.der1.append((self.values[i] - self.values[i - 1]) / (self.grid[i] - self.grid[i - 1]))           \n",
    "    \n",
    "    def der_2nd(self): # Getting the 2nd order derivatives\n",
    "        self.der2 = []\n",
    "        for i in range(2, len(self.grid) - 1):\n",
    "            self.der2.append((self.values[i + 1] - 2 * self.values[i] + self.values[i - 1]) / (self.grid_step) ** 2)\n",
    "    \n",
    "    def get_peaks(self): # Get the location of peaks using 1st order derivatives\n",
    "        self.zeros = []\n",
    "        for i in range(2, len(self.grid) - 2):\n",
    "            if self.der1[i-1]<0 and self.der1[i]>0:\n",
    "                self.zeros.append(self.grid[i+1])\n",
    "            elif self.der1[i-1]>0 and self.der1[i]<0:\n",
    "                self.zeros.append(self.grid[i+1])\n",
    "                \n",
    "    def get_widths(self): # Get the width of the peaks using 2nd order derivatives\n",
    "        self.widths = []\n",
    "        width = []\n",
    "        for i in range(2, len(self.grid) - 3):\n",
    "            if self.der2[i-1]<0 and self.der2[i]>0:\n",
    "                width.append(self.grid[i+1])\n",
    "            elif self.der2[i-1]>0 and self.der2[i]<0:\n",
    "                width.append(self.grid[i+1])\n",
    "                \n",
    "        i = 0\n",
    "        while i < (len(width) -1):\n",
    "            self.widths.append(width[i+1] - width[i])\n",
    "            i += 2\n",
    "            \n",
    "    def GMM_alike(self): # Simulate a original-alike spectra given provided information\n",
    "        x = np.arange(0, 1 + self.grid_step, self.grid_step)\n",
    "        y = np.zeros(x.shape)\n",
    "        for width, zero in zip(self.widths, self.zeros):\n",
    "            idx = np.where(self.grid == zero)\n",
    "            val = self.values[idx]\n",
    "            \n",
    "            S = width / 2\n",
    "            y += val * np.exp(- ( x - zero ) ** 2 / (2 * S **2)) \n",
    "        \n",
    "        return x, y\n",
    "    \n",
    "    def GMM(self, width_scaler, peak_shifter, peakval_shaper, noise_size, ReLU = False, transformer = 'None'): # Synthesize spectra using shifted parameters\n",
    "        x = np.arange(0, 1 + self.grid_step, self.grid_step)\n",
    "        y = np.zeros(x.shape)\n",
    "        low, high = peakval_shaper\n",
    "        for width, zero in zip(self.widths, self.zeros):\n",
    "            idx = np.where(self.grid == zero)\n",
    "            val = self.values[idx]\n",
    "            S = width / 2\n",
    "            \n",
    "            zero = zero + np.random.normal(loc = 0, scale = np.random.uniform(0, peak_shifter * width))\n",
    "            S = S + np.random.normal(loc = 0, scale = np.random.uniform(0, width_scaler * width))\n",
    "            \n",
    "            if S == 0:\n",
    "                S = width / 2\n",
    "            \n",
    "            val = val * np.random.uniform(low, high)\n",
    "            y += val * np.exp(- ( x - zero ) ** 2 / (2 * S **2)) \n",
    "        \n",
    "        y = y + np.random.normal(loc = 0.0, scale = np.random.uniform(0, noise_size), size = y.shape)\n",
    "        \n",
    "        if ReLU == True:\n",
    "            y = np.maximum(y, 0)\n",
    "        else:\n",
    "            y = (y - np.min(y)) / (np.max(y) - np.min(y))\n",
    "           \n",
    "        if transformer == 'sigmoid':\n",
    "            y = (1 - np.cos(np.pi * y)) / 2\n",
    "        elif transformer == 'squash':\n",
    "            y = np.sqrt(y)\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def processor(class_nums, level, transformer = 'None', ReLU = False, test_simulator = False):\n",
    "    \n",
    "    loc = 'Train_data/'\n",
    "    files = os.listdir(loc) # Which files are under the ZIF folder\n",
    "    files.remove('.DS_Store')\n",
    "    ##########################################################################\n",
    "    # Train Processor\n",
    "    Data = pd.DataFrame()\n",
    "    \n",
    "    if level == 'low':\n",
    "        a, b, c, d, e = 0.05, 0.05, 0.95, 1.05, 0.05\n",
    "    elif level == 'medium':\n",
    "        a, b, c, d, e = 0.25, 0.25, 0.75, 1.25, 0.25\n",
    "    else:\n",
    "        a, b, c, d, e = 0.5, 0.5, 0.5, 1.5, 0.5\n",
    "\n",
    "    for i in range(class_nums):\n",
    "\n",
    "        try:\n",
    "            cat_name = re.findall(r'XRD\\s*\\d*\\s(.*)\\.txt', files[i])[0]\n",
    "        except:\n",
    "            cat_name = re.findall(r'\\d+ MOF (.*) TXT\\.txt', files[i])[0]\n",
    "            \n",
    "        if i % 46 == 0:\n",
    "            print('Processing percentage: {}%'.format(i // 46 * 25))\n",
    "\n",
    "        with open(loc + files[i],'r') as f:\n",
    "            data = f.readlines()\n",
    "\n",
    "        data = [(lambda x: (float(x[0]), float(x[1])))(d.split()) for d in data]\n",
    "\n",
    "        df = {}\n",
    "        X = [(lambda x: x[0])(d) for d in data]\n",
    "        Y = [(lambda x: x[1])(d) for d in data]\n",
    "\n",
    "        prep = data_processes(X, Y, cat_name)\n",
    "        prep.max_min()\n",
    "        prep.fit_grid(1e-3)\n",
    "        \n",
    "        if ReLU:\n",
    "            prep.ReLU()\n",
    "        else:\n",
    "            prep.max_min()\n",
    "\n",
    "        for value, grid in zip(prep.values, prep.grid):\n",
    "            df[grid] = [value for k in range(50)]\n",
    "\n",
    "        prep.back_cancel(0)\n",
    "        prep.der_1st()\n",
    "        prep.der_2nd()\n",
    "        prep.get_peaks()\n",
    "        prep.get_widths()\n",
    "        for i in range(750):\n",
    "            X, Y = prep.GMM(a, b, (c, d), e, ReLU, transformer)\n",
    "\n",
    "            j = 0\n",
    "            for k, v in df.items():\n",
    "                df[k].append(Y[j])\n",
    "                j+=1\n",
    "\n",
    "        cols = [(lambda x: 'grid_' + str(x))(l) for l in prep.grid]\n",
    "        Df = pd.DataFrame(df)\n",
    "        Df.columns = cols\n",
    "\n",
    "        Df['label'] = prep.label\n",
    "        Df = Df.dropna()\n",
    "\n",
    "        Data = pd.concat([Data, Df], axis = 0)\n",
    "     \n",
    "    Data.head()\n",
    "    \n",
    "    if ReLU:\n",
    "        r = 'relu'\n",
    "    else:\n",
    "        r = ''\n",
    "\n",
    "    pickle_name = 'train_' + level + '_' + transformer + '_' + r + '.pickle'\n",
    "    with open(pickle_name, 'wb') as f:\n",
    "        pickle.dump(Data, f)\n",
    "        \n",
    "    ########################################################################\n",
    "    # Test Processor\n",
    "    \n",
    "    loc = 'Test_Data/'\n",
    "    Test = pd.DataFrame()\n",
    "    Files = os.listdir(loc)\n",
    "    Files.remove('.DS_Store')\n",
    "\n",
    "    for i in range(len(Files)):\n",
    "        \n",
    "        cat_name = re.findall(r'(ZIF-\\d+)\\s.*.txt',Files[i])[0]\n",
    "\n",
    "        with open(loc + Files[i],'r') as f:\n",
    "            data = f.readlines()\n",
    "        \n",
    "        new_data = []\n",
    "        for d in data:\n",
    "            try:\n",
    "                l = d.split()\n",
    "                if l != []:\n",
    "                    new_data.append((float(l[0]), float(l[1])))\n",
    "            except:\n",
    "                l = d.split(',')\n",
    "                if l != []:\n",
    "                    new_data.append((float(l[0]), float(l[1])))\n",
    "\n",
    "        data = new_data\n",
    "        \n",
    "        # 1. Normalization: X-axis and Y-axis\n",
    "\n",
    "        X = [(lambda x: x[0])(d) for d in data]\n",
    "        Y = [(lambda x: x[1])(d) for d in data]\n",
    "        # X = X[0:(int((50 - min(X)) / 0.02) + 1)]\n",
    "        # Y = Y[0:(int((50 - min(X)) / 0.02) + 1)]\n",
    "\n",
    "        prep = data_processes(X, Y, cat_name)\n",
    "        prep.max_min()\n",
    "        prep.fit_grid(1e-3)\n",
    "            \n",
    "        if test_simulator == True:\n",
    "            prep.max_min()\n",
    "            prep.back_cancel(-0.35)\n",
    "            prep.der_1st()\n",
    "            prep.der_2nd()\n",
    "            prep.get_peaks()\n",
    "            prep.get_widths()\n",
    "            X, Y = prep.GMM_alike()\n",
    "        else:\n",
    "            X, Y = prep.grid, prep.values\n",
    "        \n",
    "        if ReLU == True:\n",
    "            Y = np.maximum(Y, 0)\n",
    "        else:\n",
    "            Y = (Y - np.min(Y)) / (np.max(Y) - np.min(Y))\n",
    "           \n",
    "        if transformer == 'sigmoid':\n",
    "            Y = (1 - np.cos(np.pi * Y)) / 2\n",
    "        elif transformer == 'squash':\n",
    "            Y = np.sqrt(Y)\n",
    "\n",
    "        df = {}\n",
    "        for grid, value in zip(X, Y):\n",
    "            df[grid] = [value for k in range(2)]\n",
    "\n",
    "        cols = [(lambda x: 'grid_' + str(x))(l) for l in prep.grid]\n",
    "        Df = pd.DataFrame(df)\n",
    "        Df.columns = cols\n",
    "        Df = Df.drop(1, axis = 0)\n",
    "\n",
    "        Df['label'] = prep.label\n",
    "\n",
    "        Test= pd.concat([Test, Df], axis = 0)\n",
    "\n",
    "    Test = Test.reset_index()\n",
    "    Test = Test.drop(['index'], axis = 1)\n",
    "    Test.head()\n",
    "    \n",
    "    \n",
    "    pickle_name = 'test_' + '_' + transformer + '_' + r + '.pickle'\n",
    "    with open(pickle_name, 'wb') as f:\n",
    "        pickle.dump(Test, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing percentage: 0%\n",
      "Processing percentage: 25%\n",
      "Processing percentage: 50%\n",
      "Processing percentage: 75%\n",
      "Processing percentage: 100%\n"
     ]
    }
   ],
   "source": [
    "processor(186, 'low')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
